# Vision API PDF 변환 프로젝트 개발 일지

## 2024년 12월: 프로젝트 시작

### 12월 20일 - 첫 시도
PDF에서 텍스트를 추출하는 작업을 시작했다. 처음엔 PyPDF2를 사용했지만, 한국어와 표 구조가 완전히 깨져서 나왔다. 전통적인 OCR 방식의 한계를 실감했다.

### 12월 25일 - Vision API 도입
Claude의 Vision API를 활용하기로 결정했다. PDF를 페이지별 이미지로 변환한 후, 각 이미지를 Vision API로 처리하는 방식을 채택했다.

```python
# PDF를 이미지로 변환하는 첫 코드
doc = fitz.open(pdf_path)
for page_num, page in enumerate(doc):
    pix = page.get_pixmap(dpi=150)
    pix.save(f"page_{page_num:03d}.png")
```

## 2025년 1월: 본격 개발

### 1월 5일 - 첫 성공
2024년 데이터를 성공적으로 변환했다! 복잡한 표 구조도 대부분 정확히 인식했다. 
특히 병합된 셀이 있는 표도 Vision API가 문맥을 이해하고 적절히 처리했다.

### 1월 8일 - 확장 시도
다른 연도 데이터도 처리하기 시작했다. 2022년, 2023년, 2025년 데이터를 순차적으로 작업했다.

### 1월 10일 - 문제 발생
큰 문제를 발견했다. 2023년 데이터가 16페이지인데 결과는 50줄밖에 안 됐다. 
디버깅 결과, JSON 구조가 연도마다 달랐고, merge 스크립트가 특정 형식만 처리하고 있었다.

```python
# 문제의 코드
if 'content' in data and isinstance(data['content'], str):
    all_content.append(data['content'])
# 딕셔너리 형식의 content는 무시됨!
```

### 1월 11일 - 근본 원인 파악
각 연도별로 사용한 JSON 구조를 분석했다:
- 2022년: 단순 문자열 content
- 2023년: 구조화된 딕셔너리 content
- 2024년: 혼합 형식
- 2025년: 단순 문자열 (일부 페이지 다른 형식)

서로 다른 시점에 작업하면서 일관성을 잃었다는 것을 깨달았다.

### 1월 12일 - 범용 솔루션 개발
모든 JSON 형식을 처리할 수 있는 범용 스크립트를 개발했다.

```python
def extract_content_from_json(data):
    if isinstance(content, str):
        return content
    elif isinstance(content, dict):
        return convert_dict_to_text(content)
    # 모든 형식 자동 처리
```

결과는 성공적이었다:
- 2023년: 50줄 → 200줄 (모든 내용 복구)
- 모든 연도 정상 처리 확인

## 주요 기술적 통찰

### 1. Vision API의 강력함
복잡한 표, 수식, 특수 문자를 포함한 한국어 문서를 놀라울 정도로 정확히 인식했다. 
전통적인 OCR로는 불가능했을 작업이다.

### 2. 데이터 일관성의 중요성
"나중에 정리하자"는 생각이 큰 기술 부채가 되었다. 
처음부터 명확한 스키마를 정의했어야 했다.

### 3. 자동 검증의 필요성
수동으로 "잘 됐네"라고 판단했던 것이 실제로는 75%의 데이터가 누락된 상태였다. 
숫자로 검증하는 시스템이 필수다.

## 프로젝트 성과

- ✅ 4개 연도 데이터 성공적으로 변환
- ✅ 범용 처리 시스템 구축
- ✅ 자동 검증 체계 수립
- ✅ 재사용 가능한 파이프라인 완성

## 향후 계획

이 프로젝트의 경험을 바탕으로:
1. 다른 유형의 문서에도 적용 예정
2. 완전 자동화 파이프라인 구축 검토
3. 더 정교한 표 처리 로직 개발

---

*이 프로젝트는 실제 업무 효율화를 위해 개발되었으며, 
수작업으로 며칠 걸릴 작업을 몇 시간으로 단축시켰습니다.*