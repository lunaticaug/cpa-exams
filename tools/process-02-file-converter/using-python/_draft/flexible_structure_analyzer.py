# flexible_document_analyzer.py
# ê²½ë¡œë¥¼ ìë™ìœ¼ë¡œ ì°¾ëŠ” ë¬¸ì„œ êµ¬ì¡° ë¶„ì„ê¸°

import pathlib
import win32com.client as win32
import re
import json
from collections import defaultdict

def find_project_folders():
    """í”„ë¡œì íŠ¸ í´ë”ë“¤ì„ ìë™ìœ¼ë¡œ ì°¾ê¸°"""
    start_dir = pathlib.Path(__file__).resolve().parent
    
    # ìµœëŒ€ 3ë‹¨ê³„ ìƒìœ„ê¹Œì§€ ê²€ìƒ‰
    search_dirs = [start_dir]
    current = start_dir
    for _ in range(3):
        current = current.parent
        search_dirs.append(current)
    
    found = {}
    
    for search_dir in search_dirs:
        if not search_dir.exists():
            continue
            
        # ì¬ê·€ì ìœ¼ë¡œ í•˜ìœ„ í´ë”ë“¤ ê²€ìƒ‰
        for path in search_dir.rglob("*"):
            if not path.is_dir():
                continue
                
            folder_name = path.name.lower()
            
            # DOCX í´ë” ì°¾ê¸°
            if folder_name == "docx" and "docx" not in found:
                docx_files = list(path.glob("*.docx"))
                if docx_files:
                    found["docx"] = path
                    print(f"âœ… DOCX í´ë” ë°œê²¬: {path} ({len(docx_files)}ê°œ íŒŒì¼)")
            
            # Markdown í´ë” ì°¾ê¸°
            elif folder_name == "markdown" and "markdown" not in found:
                md_files = list(path.glob("*.md"))
                if md_files:
                    found["markdown"] = path
                    print(f"âœ… Markdown í´ë” ë°œê²¬: {path} ({len(md_files)}ê°œ íŒŒì¼)")
            
            # HWP í´ë” ì°¾ê¸°
            elif "hwp" in folder_name and "hwp" not in found:
                hwp_files = list(path.glob("*.hwp"))
                if hwp_files:
                    found["hwp"] = path
                    print(f"âœ… HWP í´ë” ë°œê²¬: {path} ({len(hwp_files)}ê°œ íŒŒì¼)")
        
        # í•„ìš”í•œ í´ë”ë“¤ì„ ëª¨ë‘ ì°¾ì•˜ìœ¼ë©´ ì¤‘ë‹¨
        if "docx" in found and "markdown" in found:
            break
    
    return found

class FlexibleDocumentAnalyzer:
    def __init__(self):
        self.paths = find_project_folders()
        
        if "docx" not in self.paths:
            raise FileNotFoundError("DOCX í´ë”ë¥¼ ì°¾ì„ ìˆ˜ ì—†ìŠµë‹ˆë‹¤.")
        if "markdown" not in self.paths:
            raise FileNotFoundError("Markdown í´ë”ë¥¼ ì°¾ì„ ìˆ˜ ì—†ìŠµë‹ˆë‹¤.")
        
        # ì¶œë ¥ í´ë” ì„¤ì •
        base_dir = self.paths["docx"].parent
        self.enhanced_dir = base_dir / "enhanced_markdown"
        self.enhanced_dir.mkdir(exist_ok=True)
        
        print(f"ğŸ“‚ DOCX: {self.paths['docx']}")
        print(f"ğŸ“‚ Markdown: {self.paths['markdown']}")
        print(f"ğŸ“‚ ì¶œë ¥: {self.enhanced_dir}")
        
        self.word = None
        self.analysis_results = []
    
    def start_word(self):
        """Word COM ê°ì²´ ì´ˆê¸°í™”"""
        self.word = win32.Dispatch("Word.Application")
        self.word.DisplayAlerts = 0
        self.word.Visible = False
    
    def quit_word(self):
        """Word COM ê°ì²´ ì¢…ë£Œ"""
        if self.word:
            self.word.Quit()
    
    def analyze_docx_structure(self, docx_path):
        """DOCX íŒŒì¼ì˜ êµ¬ì¡° ë¶„ì„"""
        try:
            doc = self.word.Documents.Open(str(docx_path))
            
            structures = {
                'tables': [],
                'images': [],
                'shapes': [],
                'charts': [],
                'total_elements': 0
            }
            
            # 1. í‘œ ë¶„ì„
            for i, table in enumerate(doc.Tables, 1):
                try:
                    table_range = table.Range
                    table_start = table_range.Start
                    table_text = table_range.Text[:100].replace('\r', ' ').replace('\n', ' ')
                    
                    structures['tables'].append({
                        'index': i,
                        'rows': table.Rows.Count,
                        'columns': table.Columns.Count,
                        'position': table_start,
                        'preview': table_text.strip(),
                        'marker': f"[TABLE_{i}_{table.Rows.Count}x{table.Columns.Count}]"
                    })
                except Exception as e:
                    structures['tables'].append({
                        'index': i,
                        'rows': '?',
                        'columns': '?',
                        'position': 0,
                        'preview': f'í‘œ ë¶„ì„ ì‹¤íŒ¨: {str(e)}',
                        'marker': f"[TABLE_{i}_ERROR]"
                    })
            
            # 2. ì´ë¯¸ì§€/ì°¨íŠ¸ ë¶„ì„
            for i, shape in enumerate(doc.InlineShapes, 1):
                try:
                    shape_range = shape.Range
                    shape_start = shape_range.Start
                    
                    if hasattr(shape, 'HasChart') and shape.HasChart:
                        structures['charts'].append({
                            'index': i,
                            'position': shape_start,
                            'type': 'Chart',
                            'marker': f"[CHART_{i}]"
                        })
                    else:
                        structures['images'].append({
                            'index': i,
                            'position': shape_start,
                            'type': 'Image',
                            'width': getattr(shape, 'Width', 0),
                            'height': getattr(shape, 'Height', 0),
                            'marker': f"[IMAGE_{i}]"
                        })
                        
                except Exception as e:
                    structures['images'].append({
                        'index': i,
                        'position': 0,
                        'type': 'Unknown',
                        'marker': f"[IMAGE_{i}_ERROR]"
                    })
            
            # 3. ë„í˜• ë¶„ì„
            for i, shape in enumerate(doc.Shapes, 1):
                try:
                    structures['shapes'].append({
                        'index': i,
                        'type': shape.Type,
                        'name': getattr(shape, 'Name', 'Unknown'),
                        'marker': f"[SHAPE_{i}]"
                    })
                except Exception as e:
                    structures['shapes'].append({
                        'index': i,
                        'type': 'Unknown',
                        'name': f'ë¶„ì„ ì‹¤íŒ¨: {str(e)}',
                        'marker': f"[SHAPE_{i}_ERROR]"
                    })
            
            structures['total_elements'] = (
                len(structures['tables']) + 
                len(structures['images']) + 
                len(structures['shapes']) + 
                len(structures['charts'])
            )
            
            doc.Close()
            return structures, doc.Content.Text if 'doc' in locals() else ""
            
        except Exception as e:
            return {'error': str(e)}, ""
    
    def enhance_markdown(self, markdown_path, structures):
        """ë§ˆí¬ë‹¤ìš´ì— êµ¬ì¡°ë¬¼ ë§ˆì»¤ ì¶”ê°€"""
        try:
            with open(markdown_path, 'r', encoding='utf-8') as f:
                content = f.read()
            
            if structures.get('total_elements', 0) == 0:
                return content, False
            
            enhanced_content = content
            insertion_markers = []
            
            # êµ¬ì¡°ë¬¼ë³„ ë§ˆì»¤ ìƒì„±
            for table in structures.get('tables', []):
                marker = f"\n\n> **ğŸ“Š í‘œ ê°ì§€ë¨ (ìœ„ì¹˜ {table['index']})**\n"
                marker += f"> - í¬ê¸°: {table['rows']}í–‰ x {table['columns']}ì—´\n"
                marker += f"> - ë¯¸ë¦¬ë³´ê¸°: {table['preview'][:50]}...\n"
                marker += f"> - ìƒíƒœ: âš ï¸ ìˆ˜ë™ í™•ì¸ í•„ìš”\n\n"
                insertion_markers.append(marker)
            
            for image in structures.get('images', []):
                marker = f"\n\n> **ğŸ–¼ï¸ ì´ë¯¸ì§€ ê°ì§€ë¨ (ìœ„ì¹˜ {image['index']})**\n"
                if image.get('width') and image.get('height'):
                    marker += f"> - í¬ê¸°: {image['width']:.0f} x {image['height']:.0f}\n"
                marker += f"> - ìƒíƒœ: âš ï¸ ìˆ˜ë™ í™•ì¸ í•„ìš”\n\n"
                insertion_markers.append(marker)
            
            for chart in structures.get('charts', []):
                marker = f"\n\n> **ğŸ“ˆ ì°¨íŠ¸ ê°ì§€ë¨ (ìœ„ì¹˜ {chart['index']})**\n"
                marker += f"> - íƒ€ì…: {chart['type']}\n"
                marker += f"> - ìƒíƒœ: âš ï¸ ìˆ˜ë™ í™•ì¸ í•„ìš”\n\n"
                insertion_markers.append(marker)
            
            for shape in structures.get('shapes', []):
                marker = f"\n\n> **ğŸ”· ë„í˜•/í…ìŠ¤íŠ¸ë°•ìŠ¤ ê°ì§€ë¨ (ìœ„ì¹˜ {shape['index']})**\n"
                marker += f"> - ì´ë¦„: {shape['name']}\n"
                marker += f"> - ìƒíƒœ: âš ï¸ ìˆ˜ë™ í™•ì¸ í•„ìš”\n\n"
                insertion_markers.append(marker)
            
            if insertion_markers:
                enhanced_content += "\n\n---\n\n## ğŸ“‹ êµ¬ì¡°ë¬¼ ë¶„ì„ ê²°ê³¼\n\n"
                enhanced_content += "".join(insertion_markers)
                
                enhanced_content += f"\n\n### ğŸ“Š ìš”ì•½\n\n"
                enhanced_content += f"- í‘œ: {len(structures.get('tables', []))}ê°œ\n"
                enhanced_content += f"- ì´ë¯¸ì§€: {len(structures.get('images', []))}ê°œ\n"
                enhanced_content += f"- ì°¨íŠ¸: {len(structures.get('charts', []))}ê°œ\n"
                enhanced_content += f"- ë„í˜•: {len(structures.get('shapes', []))}ê°œ\n"
                enhanced_content += f"- **ì´ êµ¬ì¡°ë¬¼: {structures.get('total_elements', 0)}ê°œ**\n\n"
            
            return enhanced_content, len(insertion_markers) > 0
            
        except Exception as e:
            print(f"ë§ˆí¬ë‹¤ìš´ ì²˜ë¦¬ ì‹¤íŒ¨: {e}")
            return None, False
    
    def analyze_all_documents(self):
        """ëª¨ë“  ë¬¸ì„œ ë¶„ì„"""
        docx_files = list(self.paths["docx"].glob("*.docx"))
        if not docx_files:
            print("âš ï¸ ë¶„ì„í•  DOCX íŒŒì¼ì´ ì—†ìŠµë‹ˆë‹¤.")
            return
        
        print(f"\nğŸ” ë¬¸ì„œ êµ¬ì¡° ë¶„ì„ ì‹œì‘ ({len(docx_files)}ê°œ íŒŒì¼)")
        print("=" * 60)
        
        self.start_word()
        
        files_with_structures = []
        total_structures = 0
        
        try:
            for i, docx_path in enumerate(docx_files, 1):
                print(f"\nâ–¶ [{i}/{len(docx_files)}] {docx_path.name}")
                
                structures, docx_text = self.analyze_docx_structure(docx_path)
                
                if 'error' in structures:
                    print(f"   âœ– ë¶„ì„ ì‹¤íŒ¨: {structures['error']}")
                    continue
                
                # ë§ˆí¬ë‹¤ìš´ íŒŒì¼ ì°¾ê¸°
                md_path = self.paths["markdown"] / f"{docx_path.stem}.md"
                if not md_path.exists():
                    print(f"   âš ï¸ ë§ˆí¬ë‹¤ìš´ íŒŒì¼ ì—†ìŒ: {md_path.name}")
                    continue
                
                element_count = structures.get('total_elements', 0)
                total_structures += element_count
                
                if element_count > 0:
                    files_with_structures.append({
                        'filename': docx_path.stem,
                        'structures': structures,
                        'element_count': element_count
                    })
                    
                    print(f"   ğŸ“Š êµ¬ì¡°ë¬¼ ë°œê²¬: {element_count}ê°œ")
                    
                    # ë§ˆí¬ë‹¤ìš´ ë³´ê°•
                    enhanced_content, has_markers = self.enhance_markdown(md_path, structures)
                    if enhanced_content:
                        enhanced_path = self.enhanced_dir / f"{docx_path.stem}_enhanced.md"
                        with open(enhanced_path, 'w', encoding='utf-8') as f:
                            f.write(enhanced_content)
                        print(f"   âœ” ë³´ê°• ì™„ë£Œ: {enhanced_path.name}")
                
                else:
                    print(f"   âœ” í…ìŠ¤íŠ¸ ì „ìš©")
                
                self.analysis_results.append({
                    'filename': docx_path.stem,
                    'structures': structures,
                    'element_count': element_count
                })
        
        finally:
            self.quit_word()
        
        self.generate_summary_report(files_with_structures, total_structures)
    
    def generate_summary_report(self, files_with_structures, total_structures):
        """ë¶„ì„ ê²°ê³¼ ìš”ì•½"""
        print("\n" + "=" * 60)
        print("ğŸ“‹ ë¶„ì„ ê²°ê³¼ ìš”ì•½")
        print("=" * 60)
        
        if not files_with_structures:
            print("âœ… ëª¨ë“  ë¬¸ì„œê°€ í…ìŠ¤íŠ¸ ì „ìš©ì…ë‹ˆë‹¤.")
            return
        
        print(f"ğŸ“Š êµ¬ì¡°ë¬¼ì´ ìˆëŠ” ë¬¸ì„œ: {len(files_with_structures)}ê°œ")
        print(f"ğŸ“ˆ ì´ êµ¬ì¡°ë¬¼ ê°œìˆ˜: {total_structures}ê°œ")
        
        # ê²°ê³¼ ì €ì¥
        report_path = self.enhanced_dir / "structure_analysis_report.json"
        with open(report_path, 'w', encoding='utf-8') as f:
            json.dump({
                'summary': {
                    'total_files_analyzed': len(self.analysis_results),
                    'files_with_structures': len(files_with_structures),
                    'total_structures': total_structures
                },
                'files': files_with_structures,
                'paths_used': {
                    'docx_dir': str(self.paths['docx']),
                    'markdown_dir': str(self.paths['markdown']),
                    'enhanced_dir': str(self.enhanced_dir)
                }
            }, f, ensure_ascii=False, indent=2)
        
        print(f"\nğŸ’¾ ìƒì„¸ ê²°ê³¼: {report_path}")
        print(f"ğŸ“ ë³´ê°•ëœ ë§ˆí¬ë‹¤ìš´: {self.enhanced_dir}")

def main():
    """ë©”ì¸ ì‹¤í–‰"""
    try:
        print("ğŸ”§ ìë™ ê²½ë¡œ íƒì§€ ë¬¸ì„œ êµ¬ì¡° ë¶„ì„ê¸°")
        print("=" * 60)
        
        analyzer = FlexibleDocumentAnalyzer()
        analyzer.analyze_all_documents()
        
    except FileNotFoundError as e:
        print(f"âŒ {e}")
        print("\nğŸ“ í•´ê²° ë°©ë²•:")
        print("1. path_checker.pyë¥¼ ë¨¼ì € ì‹¤í–‰í•´ì„œ í´ë” êµ¬ì¡° í™•ì¸")
        print("2. ë˜ëŠ” docx, markdown í´ë”ê°€ ìˆëŠ” ë””ë ‰í† ë¦¬ì—ì„œ ì‹¤í–‰")
    except Exception as e:
        print(f"âŒ ì˜¤ë¥˜ ë°œìƒ: {e}")

if __name__ == "__main__":
    main()