# document_structure_analyzer.py
# DOCX íŒŒì¼ì˜ êµ¬ì¡°ë¬¼(í‘œ, ì´ë¯¸ì§€, ê·¸ë˜í”„)ì„ ë¶„ì„í•˜ê³  ë§ˆí¬ë‹¤ìš´ì— í‘œì‹œ

import pathlib
import win32com.client as win32
import re
import json
from collections import defaultdict

class DocumentStructureAnalyzer:
    def __init__(self, docx_dir, markdown_dir):
        self.docx_dir = pathlib.Path(docx_dir)
        self.markdown_dir = pathlib.Path(markdown_dir)
        self.enhanced_dir = self.markdown_dir.parent / "enhanced_markdown"
        self.enhanced_dir.mkdir(exist_ok=True)
        
        self.word = None
        self.analysis_results = []
    
    def start_word(self):
        """Word COM ê°ì²´ ì´ˆê¸°í™”"""
        self.word = win32.Dispatch("Word.Application")
        self.word.DisplayAlerts = 0
        self.word.Visible = False
    
    def quit_word(self):
        """Word COM ê°ì²´ ì¢…ë£Œ"""
        if self.word:
            self.word.Quit()
    
    def analyze_docx_structure(self, docx_path):
        """DOCX íŒŒì¼ì˜ êµ¬ì¡° ë¶„ì„"""
        try:
            doc = self.word.Documents.Open(str(docx_path))
            
            # ë¬¸ì„œ ì „ì²´ í…ìŠ¤íŠ¸ ê°€ì ¸ì˜¤ê¸° (ìœ„ì¹˜ ì •ë³´ í¬í•¨)
            full_text = doc.Content.Text
            
            structures = {
                'tables': [],
                'images': [],
                'shapes': [],
                'charts': [],
                'total_elements': 0
            }
            
            # 1. í‘œ ë¶„ì„
            for i, table in enumerate(doc.Tables, 1):
                try:
                    # í‘œì˜ ëŒ€ëµì ì¸ ìœ„ì¹˜ ì°¾ê¸°
                    table_range = table.Range
                    table_start = table_range.Start
                    table_text = table_range.Text[:100].replace('\r', ' ').replace('\n', ' ')
                    
                    structures['tables'].append({
                        'index': i,
                        'rows': table.Rows.Count,
                        'columns': table.Columns.Count,
                        'position': table_start,
                        'preview': table_text.strip(),
                        'marker': f"[TABLE_{i}_{table.Rows.Count}x{table.Columns.Count}]"
                    })
                except Exception as e:
                    structures['tables'].append({
                        'index': i,
                        'rows': '?',
                        'columns': '?',
                        'position': 0,
                        'preview': f'í‘œ ë¶„ì„ ì‹¤íŒ¨: {str(e)}',
                        'marker': f"[TABLE_{i}_ERROR]"
                    })
            
            # 2. ì¸ë¼ì¸ ì´ë¯¸ì§€/ì°¨íŠ¸ ë¶„ì„
            for i, shape in enumerate(doc.InlineShapes, 1):
                try:
                    shape_range = shape.Range
                    shape_start = shape_range.Start
                    
                    # íƒ€ì… í™•ì¸
                    shape_type = "IMAGE"
                    if hasattr(shape, 'HasChart') and shape.HasChart:
                        shape_type = "CHART"
                        structures['charts'].append({
                            'index': i,
                            'position': shape_start,
                            'type': 'Chart',
                            'marker': f"[CHART_{i}]"
                        })
                    else:
                        structures['images'].append({
                            'index': i,
                            'position': shape_start,
                            'type': 'Image',
                            'width': getattr(shape, 'Width', 0),
                            'height': getattr(shape, 'Height', 0),
                            'marker': f"[IMAGE_{i}]"
                        })
                        
                except Exception as e:
                    structures['images'].append({
                        'index': i,
                        'position': 0,
                        'type': 'Unknown',
                        'marker': f"[IMAGE_{i}_ERROR]"
                    })
            
            # 3. ë„í˜•/í…ìŠ¤íŠ¸ë°•ìŠ¤ ë¶„ì„
            for i, shape in enumerate(doc.Shapes, 1):
                try:
                    # ë„í˜•ì˜ ëŒ€ëµì ì¸ ìœ„ì¹˜ (ì •í™•í•˜ì§€ ì•Šì„ ìˆ˜ ìˆìŒ)
                    structures['shapes'].append({
                        'index': i,
                        'type': shape.Type,
                        'name': getattr(shape, 'Name', 'Unknown'),
                        'marker': f"[SHAPE_{i}]"
                    })
                except Exception as e:
                    structures['shapes'].append({
                        'index': i,
                        'type': 'Unknown',
                        'name': f'ë¶„ì„ ì‹¤íŒ¨: {str(e)}',
                        'marker': f"[SHAPE_{i}_ERROR]"
                    })
            
            # ì´ êµ¬ì¡°ë¬¼ ê°œìˆ˜
            structures['total_elements'] = (
                len(structures['tables']) + 
                len(structures['images']) + 
                len(structures['shapes']) + 
                len(structures['charts'])
            )
            
            doc.Close()
            return structures, full_text
            
        except Exception as e:
            return {'error': str(e)}, ""
    
    def find_insertion_points(self, markdown_text, docx_text, structures):
        """ë§ˆí¬ë‹¤ìš´ì—ì„œ êµ¬ì¡°ë¬¼ ì‚½ì… ìœ„ì¹˜ ì°¾ê¸°"""
        # ë‹¨ë½ë³„ë¡œ ë‚˜ëˆ„ì–´ ë§¤ì¹­ ì‹œë„
        md_paragraphs = [p.strip() for p in markdown_text.split('\n\n') if p.strip()]
        docx_paragraphs = [p.strip() for p in docx_text.split('\n\n') if p.strip()]
        
        # í…ìŠ¤íŠ¸ ìœ„ì¹˜ë³„ë¡œ êµ¬ì¡°ë¬¼ ì •ë ¬
        all_elements = []
        
        for table in structures.get('tables', []):
            all_elements.append(('table', table['position'], table))
        
        for image in structures.get('images', []):
            all_elements.append(('image', image['position'], image))
        
        for chart in structures.get('charts', []):
            all_elements.append(('chart', chart['position'], chart))
        
        # ìœ„ì¹˜ìˆœìœ¼ë¡œ ì •ë ¬
        all_elements.sort(key=lambda x: x[1])
        
        return all_elements
    
    def enhance_markdown(self, markdown_path, structures, docx_text):
        """ë§ˆí¬ë‹¤ìš´ì— êµ¬ì¡°ë¬¼ ë§ˆì»¤ ì¶”ê°€"""
        try:
            with open(markdown_path, 'r', encoding='utf-8') as f:
                content = f.read()
            
            # êµ¬ì¡°ë¬¼ì´ ì—†ìœ¼ë©´ ì›ë³¸ ë°˜í™˜
            if structures.get('total_elements', 0) == 0:
                return content, False
            
            enhanced_content = content
            insertion_markers = []
            
            # í‘œ ë§ˆì»¤ ì¶”ê°€
            for table in structures.get('tables', []):
                marker = f"\n\n> **ğŸ“Š í‘œ ê°ì§€ë¨ (ìœ„ì¹˜ {table['index']})**\n"
                marker += f"> - í¬ê¸°: {table['rows']}í–‰ x {table['columns']}ì—´\n"
                marker += f"> - ë¯¸ë¦¬ë³´ê¸°: {table['preview'][:50]}...\n"
                marker += f"> - ìƒíƒœ: âš ï¸ ìˆ˜ë™ í™•ì¸ í•„ìš”\n\n"
                marker += f"<!-- {table['marker']} -->\n\n"
                insertion_markers.append(marker)
            
            # ì´ë¯¸ì§€ ë§ˆì»¤ ì¶”ê°€
            for image in structures.get('images', []):
                marker = f"\n\n> **ğŸ–¼ï¸ ì´ë¯¸ì§€ ê°ì§€ë¨ (ìœ„ì¹˜ {image['index']})**\n"
                if image.get('width') and image.get('height'):
                    marker += f"> - í¬ê¸°: {image['width']:.0f} x {image['height']:.0f}\n"
                marker += f"> - ìƒíƒœ: âš ï¸ ìˆ˜ë™ í™•ì¸ í•„ìš”\n\n"
                marker += f"<!-- {image['marker']} -->\n\n"
                insertion_markers.append(marker)
            
            # ì°¨íŠ¸ ë§ˆì»¤ ì¶”ê°€
            for chart in structures.get('charts', []):
                marker = f"\n\n> **ğŸ“ˆ ì°¨íŠ¸ ê°ì§€ë¨ (ìœ„ì¹˜ {chart['index']})**\n"
                marker += f"> - íƒ€ì…: {chart['type']}\n"
                marker += f"> - ìƒíƒœ: âš ï¸ ìˆ˜ë™ í™•ì¸ í•„ìš”\n\n"
                marker += f"<!-- {chart['marker']} -->\n\n"
                insertion_markers.append(marker)
            
            # ë„í˜• ë§ˆì»¤ ì¶”ê°€
            for shape in structures.get('shapes', []):
                marker = f"\n\n> **ğŸ”· ë„í˜•/í…ìŠ¤íŠ¸ë°•ìŠ¤ ê°ì§€ë¨ (ìœ„ì¹˜ {shape['index']})**\n"
                marker += f"> - ì´ë¦„: {shape['name']}\n"
                marker += f"> - ìƒíƒœ: âš ï¸ ìˆ˜ë™ í™•ì¸ í•„ìš”\n\n"
                marker += f"<!-- {shape['marker']} -->\n\n"
                insertion_markers.append(marker)
            
            # ë§ˆì»¤ë“¤ì„ ë¬¸ì„œ ëì— ì¶”ê°€ (ê°„ë‹¨í•œ ë°©ë²•)
            if insertion_markers:
                enhanced_content += "\n\n---\n\n## ğŸ“‹ êµ¬ì¡°ë¬¼ ë¶„ì„ ê²°ê³¼\n\n"
                enhanced_content += "".join(insertion_markers)
                
                # ìš”ì•½ ì •ë³´ ì¶”ê°€
                enhanced_content += f"\n\n### ğŸ“Š ìš”ì•½\n\n"
                enhanced_content += f"- í‘œ: {len(structures.get('tables', []))}ê°œ\n"
                enhanced_content += f"- ì´ë¯¸ì§€: {len(structures.get('images', []))}ê°œ\n"
                enhanced_content += f"- ì°¨íŠ¸: {len(structures.get('charts', []))}ê°œ\n"
                enhanced_content += f"- ë„í˜•: {len(structures.get('shapes', []))}ê°œ\n"
                enhanced_content += f"- **ì´ êµ¬ì¡°ë¬¼: {structures.get('total_elements', 0)}ê°œ**\n\n"
                enhanced_content += "> âš ï¸ **ì£¼ì˜**: ìœ„ êµ¬ì¡°ë¬¼ë“¤ì€ ìë™ ë³€í™˜ë˜ì§€ ì•Šì•˜ì„ ìˆ˜ ìˆìŠµë‹ˆë‹¤. ì›ë³¸ ë¬¸ì„œì™€ ë¹„êµí•˜ì—¬ ìˆ˜ë™ìœ¼ë¡œ í™•ì¸í•´ì£¼ì„¸ìš”.\n"
            
            return enhanced_content, len(insertion_markers) > 0
            
        except Exception as e:
            print(f"ë§ˆí¬ë‹¤ìš´ ë³´ê°• ì‹¤íŒ¨: {e}")
            return None, False
    
    def analyze_all_documents(self):
        """ëª¨ë“  ë¬¸ì„œ ë¶„ì„ ë° ì²˜ë¦¬"""
        docx_files = list(self.docx_dir.glob("*.docx"))
        if not docx_files:
            print("âš ï¸ ë¶„ì„í•  DOCX íŒŒì¼ì´ ì—†ìŠµë‹ˆë‹¤.")
            return
        
        print(f"ğŸ” ë¬¸ì„œ êµ¬ì¡° ë¶„ì„ ì‹œì‘ ({len(docx_files)}ê°œ íŒŒì¼)")
        print("=" * 60)
        
        self.start_word()
        
        files_with_structures = []
        total_structures = 0
        
        try:
            for i, docx_path in enumerate(docx_files, 1):
                print(f"\nâ–¶ [{i}/{len(docx_files)}] {docx_path.name}")
                
                # DOCX êµ¬ì¡° ë¶„ì„
                structures, docx_text = self.analyze_docx_structure(docx_path)
                
                if 'error' in structures:
                    print(f"   âœ– ë¶„ì„ ì‹¤íŒ¨: {structures['error']}")
                    continue
                
                # ëŒ€ì‘í•˜ëŠ” ë§ˆí¬ë‹¤ìš´ íŒŒì¼ ì°¾ê¸°
                md_path = self.markdown_dir / f"{docx_path.stem}.md"
                if not md_path.exists():
                    print(f"   âš ï¸ ë§ˆí¬ë‹¤ìš´ íŒŒì¼ ì—†ìŒ: {md_path.name}")
                    continue
                
                # êµ¬ì¡°ë¬¼ ê°œìˆ˜ í™•ì¸
                element_count = structures.get('total_elements', 0)
                total_structures += element_count
                
                if element_count > 0:
                    files_with_structures.append({
                        'filename': docx_path.stem,
                        'structures': structures,
                        'element_count': element_count
                    })
                    
                    print(f"   ğŸ“Š êµ¬ì¡°ë¬¼ ë°œê²¬: {element_count}ê°œ")
                    print(f"      - í‘œ: {len(structures.get('tables', []))}ê°œ")
                    print(f"      - ì´ë¯¸ì§€: {len(structures.get('images', []))}ê°œ")
                    print(f"      - ì°¨íŠ¸: {len(structures.get('charts', []))}ê°œ")
                    print(f"      - ë„í˜•: {len(structures.get('shapes', []))}ê°œ")
                    
                    # ë§ˆí¬ë‹¤ìš´ ë³´ê°•
                    enhanced_content, has_markers = self.enhance_markdown(md_path, structures, docx_text)
                    if enhanced_content:
                        enhanced_path = self.enhanced_dir / f"{docx_path.stem}_enhanced.md"
                        with open(enhanced_path, 'w', encoding='utf-8') as f:
                            f.write(enhanced_content)
                        print(f"   âœ” ë³´ê°•ëœ ë§ˆí¬ë‹¤ìš´ ìƒì„±: {enhanced_path.name}")
                    
                else:
                    print(f"   âœ” êµ¬ì¡°ë¬¼ ì—†ìŒ (í…ìŠ¤íŠ¸ë§Œ)")
                
                # ë¶„ì„ ê²°ê³¼ ì €ì¥
                self.analysis_results.append({
                    'filename': docx_path.stem,
                    'structures': structures,
                    'element_count': element_count
                })
        
        finally:
            self.quit_word()
        
        # ê²°ê³¼ ìš”ì•½
        self.generate_summary_report(files_with_structures, total_structures)
    
    def generate_summary_report(self, files_with_structures, total_structures):
        """ë¶„ì„ ê²°ê³¼ ìš”ì•½ ë¦¬í¬íŠ¸ ìƒì„±"""
        print("\n" + "=" * 60)
        print("ğŸ“‹ ë¶„ì„ ê²°ê³¼ ìš”ì•½")
        print("=" * 60)
        
        if not files_with_structures:
            print("âœ… ëª¨ë“  ë¬¸ì„œê°€ í…ìŠ¤íŠ¸ ì „ìš©ì…ë‹ˆë‹¤. ì¶”ê°€ ë³´ì™„ì´ í•„ìš”í•˜ì§€ ì•ŠìŠµë‹ˆë‹¤.")
            return
        
        print(f"ğŸ“Š êµ¬ì¡°ë¬¼ì´ ìˆëŠ” ë¬¸ì„œ: {len(files_with_structures)}ê°œ")
        print(f"ğŸ“ˆ ì´ êµ¬ì¡°ë¬¼ ê°œìˆ˜: {total_structures}ê°œ")
        
        # êµ¬ì¡°ë¬¼ë³„ í†µê³„
        table_count = sum(len(f['structures'].get('tables', [])) for f in files_with_structures)
        image_count = sum(len(f['structures'].get('images', [])) for f in files_with_structures)
        chart_count = sum(len(f['structures'].get('charts', [])) for f in files_with_structures)
        shape_count = sum(len(f['structures'].get('shapes', [])) for f in files_with_structures)
        
        print(f"\nğŸ“Š êµ¬ì¡°ë¬¼ ìœ í˜•ë³„ í†µê³„:")
        print(f"   - í‘œ: {table_count}ê°œ")
        print(f"   - ì´ë¯¸ì§€: {image_count}ê°œ")
        print(f"   - ì°¨íŠ¸: {chart_count}ê°œ")
        print(f"   - ë„í˜•: {shape_count}ê°œ")
        
        # ìƒìœ„ 10ê°œ ë¬¸ì„œ (êµ¬ì¡°ë¬¼ ë§ì€ ìˆœ)
        files_with_structures.sort(key=lambda x: x['element_count'], reverse=True)
        
        print(f"\nğŸ” êµ¬ì¡°ë¬¼ì´ ë§ì€ ë¬¸ì„œ Top 10:")
        for i, file_info in enumerate(files_with_structures[:10], 1):
            filename = file_info['filename']
            count = file_info['element_count']
            structures = file_info['structures']
            
            print(f"   {i:2d}. {filename} ({count}ê°œ)")
            print(f"       í‘œ:{len(structures.get('tables', []))}, "
                  f"ì´ë¯¸ì§€:{len(structures.get('images', []))}, "
                  f"ì°¨íŠ¸:{len(structures.get('charts', []))}, "
                  f"ë„í˜•:{len(structures.get('shapes', []))}")
        
        # ê²°ê³¼ íŒŒì¼ ì €ì¥
        report_path = self.enhanced_dir / "structure_analysis_report.json"
        with open(report_path, 'w', encoding='utf-8') as f:
            json.dump({
                'summary': {
                    'total_files_analyzed': len(self.analysis_results),
                    'files_with_structures': len(files_with_structures),
                    'total_structures': total_structures,
                    'structure_counts': {
                        'tables': table_count,
                        'images': image_count,
                        'charts': chart_count,
                        'shapes': shape_count
                    }
                },
                'files': files_with_structures
            }, f, ensure_ascii=False, indent=2)
        
        print(f"\nğŸ’¾ ìƒì„¸ ë¶„ì„ ê²°ê³¼ê°€ ì €ì¥ë˜ì—ˆìŠµë‹ˆë‹¤: {report_path}")
        print(f"ğŸ“ ë³´ê°•ëœ ë§ˆí¬ë‹¤ìš´ íŒŒì¼ë“¤: {self.enhanced_dir}")
        
        print(f"\nğŸ’¡ ë‹¤ìŒ ë‹¨ê³„:")
        print(f"   1. enhanced_markdown í´ë”ì˜ íŒŒì¼ë“¤ì„ í™•ì¸í•˜ì„¸ìš”")
        print(f"   2. ê° êµ¬ì¡°ë¬¼ ë§ˆì»¤(ğŸ“Š ğŸ“ˆ ğŸ–¼ï¸)ë¥¼ ì°¾ì•„ ì›ë³¸ê³¼ ë¹„êµí•˜ì„¸ìš”")
        print(f"   3. í•„ìš”í•œ ê²½ìš° ìˆ˜ë™ìœ¼ë¡œ í‘œ/ì´ë¯¸ì§€ë¥¼ ë§ˆí¬ë‹¤ìš´ìœ¼ë¡œ ë³€í™˜í•˜ì„¸ìš”")

def main():
    """ë©”ì¸ ì‹¤í–‰ í•¨ìˆ˜"""
    script_dir = pathlib.Path(__file__).resolve().parent
    docx_dir = script_dir / "docx"
    markdown_dir = script_dir / "markdown"
    
    if not docx_dir.exists():
        print(f"âŒ DOCX í´ë”ë¥¼ ì°¾ì„ ìˆ˜ ì—†ìŠµë‹ˆë‹¤: {docx_dir}")
        return
    
    if not markdown_dir.exists():
        print(f"âŒ Markdown í´ë”ë¥¼ ì°¾ì„ ìˆ˜ ì—†ìŠµë‹ˆë‹¤: {markdown_dir}")
        return
    
    analyzer = DocumentStructureAnalyzer(docx_dir, markdown_dir)
    analyzer.analyze_all_documents()

if __name__ == "__main__":
    main()